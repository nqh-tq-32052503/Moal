{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2468e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Moal'...\n",
      "remote: Enumerating objects: 170, done.\u001b[K\n",
      "remote: Counting objects: 100% (170/170), done.\u001b[K\n",
      "remote: Compressing objects: 100% (137/137), done.\u001b[K\n",
      "remote: Total 170 (delta 74), reused 63 (delta 30), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (170/170), 460.22 KiB | 15.87 MiB/s, done.\n",
      "Resolving deltas: 100% (74/74), done.\n",
      "/content/Moal\n"
     ]
    }
   ],
   "source": [
    "!rm -rf /content/Moal\n",
    "!git clone https://github.com/nqh-tq-32052503/Moal.git\n",
    "%cd /content/Moal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c1f2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from Moal.backbone.vision_transformer_adapter import vit_base_patch16_224_bilora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d5f3098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = vit_base_patch16_224_bilora(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9cf4859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29071488"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Moal.utils.toolkit import count_parameters\n",
    "count_parameters(model, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f84c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 224, 224])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 2 \n",
    "dummy_input = torch.randn(\n",
    "    batch_size,\n",
    "    3, 224, 224,\n",
    "    dtype=torch.float32,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "print(dummy_input.shape)  # (B, 3, 224, 224)\n",
    "print(dummy_input.dtype)  # torch.float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54df58e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.forward(dummy_input, task=0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee44a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Moal.backbone.vision_transformer_adapter import vit_base_patch16_224_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1a0afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "tuning_config = EasyDict(\n",
    "    # AdaptFormer.\n",
    "    ffn_adapt=True,\n",
    "    ffn_option=\"parallel\",\n",
    "    ffn_adapter_layernorm_option=\"none\",\n",
    "    ffn_adapter_init_option=\"lora\",\n",
    "    ffn_adapter_scalar=\"0.1\",\n",
    "    ffn_num=64,\n",
    "    d_model=768,\n",
    "    # VPT related\n",
    "    vpt_on=False,\n",
    "    vpt_num=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ceee2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm using ViT with adapters.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac30ac1b11ab44e8bf380531a0b1742a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['blocks.0.adaptmlp.down_proj.weight', 'blocks.0.adaptmlp.down_proj.bias', 'blocks.0.adaptmlp.up_proj.weight', 'blocks.0.adaptmlp.up_proj.bias', 'blocks.1.adaptmlp.down_proj.weight', 'blocks.1.adaptmlp.down_proj.bias', 'blocks.1.adaptmlp.up_proj.weight', 'blocks.1.adaptmlp.up_proj.bias', 'blocks.2.adaptmlp.down_proj.weight', 'blocks.2.adaptmlp.down_proj.bias', 'blocks.2.adaptmlp.up_proj.weight', 'blocks.2.adaptmlp.up_proj.bias', 'blocks.3.adaptmlp.down_proj.weight', 'blocks.3.adaptmlp.down_proj.bias', 'blocks.3.adaptmlp.up_proj.weight', 'blocks.3.adaptmlp.up_proj.bias', 'blocks.4.adaptmlp.down_proj.weight', 'blocks.4.adaptmlp.down_proj.bias', 'blocks.4.adaptmlp.up_proj.weight', 'blocks.4.adaptmlp.up_proj.bias', 'blocks.5.adaptmlp.down_proj.weight', 'blocks.5.adaptmlp.down_proj.bias', 'blocks.5.adaptmlp.up_proj.weight', 'blocks.5.adaptmlp.up_proj.bias', 'blocks.6.adaptmlp.down_proj.weight', 'blocks.6.adaptmlp.down_proj.bias', 'blocks.6.adaptmlp.up_proj.weight', 'blocks.6.adaptmlp.up_proj.bias', 'blocks.7.adaptmlp.down_proj.weight', 'blocks.7.adaptmlp.down_proj.bias', 'blocks.7.adaptmlp.up_proj.weight', 'blocks.7.adaptmlp.up_proj.bias', 'blocks.8.adaptmlp.down_proj.weight', 'blocks.8.adaptmlp.down_proj.bias', 'blocks.8.adaptmlp.up_proj.weight', 'blocks.8.adaptmlp.up_proj.bias', 'blocks.9.adaptmlp.down_proj.weight', 'blocks.9.adaptmlp.down_proj.bias', 'blocks.9.adaptmlp.up_proj.weight', 'blocks.9.adaptmlp.up_proj.bias', 'blocks.10.adaptmlp.down_proj.weight', 'blocks.10.adaptmlp.down_proj.bias', 'blocks.10.adaptmlp.up_proj.weight', 'blocks.10.adaptmlp.up_proj.bias', 'blocks.11.adaptmlp.down_proj.weight', 'blocks.11.adaptmlp.down_proj.bias', 'blocks.11.adaptmlp.up_proj.weight', 'blocks.11.adaptmlp.up_proj.bias'], unexpected_keys=[])\n"
     ]
    }
   ],
   "source": [
    "ref_model = vit_base_patch16_224_adapter(num_classes=0,\n",
    "                    global_pool=False, drop_path_rate=0.0, tuning_config=tuning_config)\n",
    "ref_model.out_dim=768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de4df365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_y = ref_model.forward(dummy_input)\n",
    "ref_y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
