{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/nqh-tq-32052503/Moal.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T08:58:57.638760Z","iopub.execute_input":"2025-12-13T08:58:57.639069Z","iopub.status.idle":"2025-12-13T08:58:58.355014Z","shell.execute_reply.started":"2025-12-13T08:58:57.639010Z","shell.execute_reply":"2025-12-13T08:58:58.354280Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'Moal'...\nremote: Enumerating objects: 135, done.\u001b[K\nremote: Counting objects: 100% (135/135), done.\u001b[K\nremote: Compressing objects: 100% (116/116), done.\u001b[K\nremote: Total 135 (delta 48), reused 41 (delta 16), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (135/135), 442.67 KiB | 11.96 MiB/s, done.\nResolving deltas: 100% (48/48), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd /kaggle/working/Moal/Moal\n\nimport os\nos.makedirs(\"/root/autodl-tmp/data/cifar224\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T08:58:58.356425Z","iopub.execute_input":"2025-12-13T08:58:58.356654Z","iopub.status.idle":"2025-12-13T08:58:58.362769Z","shell.execute_reply.started":"2025-12-13T08:58:58.356630Z","shell.execute_reply":"2025-12-13T08:58:58.362259Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/Moal/Moal\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import json\n\nwith open(\"exps/Moal_cifar224.json\", \"r\") as f:\n    args = json.load(f)\nprint(type(args))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T08:58:58.363378Z","iopub.execute_input":"2025-12-13T08:58:58.363549Z","iopub.status.idle":"2025-12-13T08:58:58.378282Z","shell.execute_reply.started":"2025-12-13T08:58:58.363536Z","shell.execute_reply":"2025-12-13T08:58:58.377430Z"}},"outputs":[{"name":"stdout","text":"<class 'dict'>\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from utils.data_manager import DataManager\nfrom utils import factory\nfrom utils.toolkit import count_parameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T08:58:58.379968Z","iopub.execute_input":"2025-12-13T08:58:58.380510Z","iopub.status.idle":"2025-12-13T08:59:04.638418Z","shell.execute_reply.started":"2025-12-13T08:58:58.380493Z","shell.execute_reply":"2025-12-13T08:59:04.637638Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data_manager = DataManager(\n        args[\"dataset\"],\n        args[\"shuffle\"],\n        args[\"seed\"],\n        args[\"init_cls\"],\n        args[\"increment\"],\n        args,\n        \"/root/autodl-tmp/data/cifar224\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T08:59:04.639259Z","iopub.execute_input":"2025-12-13T08:59:04.639708Z","iopub.status.idle":"2025-12-13T08:59:13.439716Z","shell.execute_reply.started":"2025-12-13T08:59:04.639684Z","shell.execute_reply":"2025-12-13T08:59:13.438986Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 169M/169M [00:05<00:00, 32.7MB/s] \n","output_type":"stream"},{"name":"stdout","text":"[43, 92, 14, 57, 89, 20, 34, 69, 21, 3, 77, 33, 54, 86, 49, 79, 98, 15, 16, 61, 46, 59, 39, 12, 56, 50, 27, 87, 45, 78, 24, 0, 7, 51, 4, 73, 8, 35, 10, 13, 70, 74, 31, 55, 82, 5, 67, 75, 22, 76, 47, 83, 90, 1, 6, 84, 94, 66, 88, 91, 23, 29, 64, 37, 72, 18, 11, 44, 40, 93, 80, 30, 81, 68, 32, 58, 63, 2, 17, 65, 38, 41, 97, 48, 25, 28, 52, 99, 9, 36, 85, 62, 60, 96, 95, 53, 19, 42, 26, 71]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"args[\"nb_classes\"] = data_manager.nb_classes # update args\nargs[\"nb_tasks\"] = data_manager.nb_tasks\nargs[\"model_name\"] = \"adapt_ac_com_sdc_ema_auto\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T08:59:13.440431Z","iopub.execute_input":"2025-12-13T08:59:13.440684Z","iopub.status.idle":"2025-12-13T08:59:13.444712Z","shell.execute_reply.started":"2025-12-13T08:59:13.440664Z","shell.execute_reply":"2025-12-13T08:59:13.443899Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"model = factory.get_model(args[\"model_name\"], args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T08:59:13.445406Z","iopub.execute_input":"2025-12-13T08:59:13.445639Z","iopub.status.idle":"2025-12-13T08:59:21.296862Z","shell.execute_reply.started":"2025-12-13T08:59:13.445615Z","shell.execute_reply":"2025-12-13T08:59:21.296165Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"This is for the BaseNet initialization.\nI'm using ViT with adapters.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"992dd507a0b846ad9501b4ce1e5bf35f"}},"metadata":{}},{"name":"stdout","text":"_IncompatibleKeys(missing_keys=['blocks.0.adaptmlp.down_proj.weight', 'blocks.0.adaptmlp.down_proj.bias', 'blocks.0.adaptmlp.up_proj.weight', 'blocks.0.adaptmlp.up_proj.bias', 'blocks.1.adaptmlp.down_proj.weight', 'blocks.1.adaptmlp.down_proj.bias', 'blocks.1.adaptmlp.up_proj.weight', 'blocks.1.adaptmlp.up_proj.bias', 'blocks.2.adaptmlp.down_proj.weight', 'blocks.2.adaptmlp.down_proj.bias', 'blocks.2.adaptmlp.up_proj.weight', 'blocks.2.adaptmlp.up_proj.bias', 'blocks.3.adaptmlp.down_proj.weight', 'blocks.3.adaptmlp.down_proj.bias', 'blocks.3.adaptmlp.up_proj.weight', 'blocks.3.adaptmlp.up_proj.bias', 'blocks.4.adaptmlp.down_proj.weight', 'blocks.4.adaptmlp.down_proj.bias', 'blocks.4.adaptmlp.up_proj.weight', 'blocks.4.adaptmlp.up_proj.bias', 'blocks.5.adaptmlp.down_proj.weight', 'blocks.5.adaptmlp.down_proj.bias', 'blocks.5.adaptmlp.up_proj.weight', 'blocks.5.adaptmlp.up_proj.bias', 'blocks.6.adaptmlp.down_proj.weight', 'blocks.6.adaptmlp.down_proj.bias', 'blocks.6.adaptmlp.up_proj.weight', 'blocks.6.adaptmlp.up_proj.bias', 'blocks.7.adaptmlp.down_proj.weight', 'blocks.7.adaptmlp.down_proj.bias', 'blocks.7.adaptmlp.up_proj.weight', 'blocks.7.adaptmlp.up_proj.bias', 'blocks.8.adaptmlp.down_proj.weight', 'blocks.8.adaptmlp.down_proj.bias', 'blocks.8.adaptmlp.up_proj.weight', 'blocks.8.adaptmlp.up_proj.bias', 'blocks.9.adaptmlp.down_proj.weight', 'blocks.9.adaptmlp.down_proj.bias', 'blocks.9.adaptmlp.up_proj.weight', 'blocks.9.adaptmlp.up_proj.bias', 'blocks.10.adaptmlp.down_proj.weight', 'blocks.10.adaptmlp.down_proj.bias', 'blocks.10.adaptmlp.up_proj.weight', 'blocks.10.adaptmlp.up_proj.bias', 'blocks.11.adaptmlp.down_proj.weight', 'blocks.11.adaptmlp.down_proj.bias', 'blocks.11.adaptmlp.up_proj.weight', 'blocks.11.adaptmlp.up_proj.bias'], unexpected_keys=[])\nAfter BaseNet initialization.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import logging\ncnn_curve, nme_curve = {\"top1\": [], \"top5\": []}, {\"top1\": [], \"top5\": []}\n\nall_his_acc = []\nfor task in range(data_manager.nb_tasks):\n    logging.info(\"All params: {}\".format(count_parameters(model._network)))\n    logging.info(\n        \"Trainable params: {}\".format(count_parameters(model._network, True))\n    )\n    model.incremental_train(data_manager)\n    cnn_accy, nme_accy = model.eval_task()\n    model.after_task()\n\n    if nme_accy is not None:\n        logging.info(\"CNN: {}\".format(cnn_accy[\"grouped\"]))\n        logging.info(\"NME: {}\".format(nme_accy[\"grouped\"]))\n\n        all_his_acc.append(cnn_accy[\"grouped\"].values())\n        cnn_curve[\"top1\"].append(cnn_accy[\"top1\"])\n        cnn_curve[\"top5\"].append(cnn_accy[\"top5\"])\n\n        nme_curve[\"top1\"].append(nme_accy[\"top1\"])\n        nme_curve[\"top5\"].append(nme_accy[\"top5\"])\n\n        logging.info(\"CNN top1 curve: {}\".format(cnn_curve[\"top1\"]))\n        logging.info(\"CNN top5 curve: {}\".format(cnn_curve[\"top5\"]))\n        logging.info(\"NME top1 curve: {}\".format(nme_curve[\"top1\"]))\n        logging.info(\"NME top5 curve: {}\\n\".format(nme_curve[\"top5\"]))\n\n        print('Average Accuracy (CNN):', sum(cnn_curve[\"top1\"])/len(cnn_curve[\"top1\"]))\n        print('Average Accuracy (NME):', sum(nme_curve[\"top1\"])/len(nme_curve[\"top1\"]))\n\n        logging.info(\"Average Accuracy (CNN): {}\".format(sum(cnn_curve[\"top1\"])/len(cnn_curve[\"top1\"])))\n        logging.info(\"Average Accuracy (NME): {}\".format(sum(nme_curve[\"top1\"])/len(nme_curve[\"top1\"])))\n    else:\n        logging.info(\"No NME accuracy.\")\n        logging.info(\"CNN: {}\".format(cnn_accy[\"grouped\"]))\n\n        cnn_accy[\"grouped\"].pop('total')\n        cnn_accy[\"grouped\"].pop('old')\n        cnn_accy[\"grouped\"].pop('new')\n        all_his_acc.append(list(cnn_accy[\"grouped\"].values()))\n\n        cnn_curve[\"top1\"].append(cnn_accy[\"top1\"])\n        cnn_curve[\"top5\"].append(cnn_accy[\"top5\"])\n\n        logging.info(\"CNN top1 curve: {}\".format(cnn_curve[\"top1\"]))\n        logging.info(\"CNN top5 curve: {}\\n\".format(cnn_curve[\"top5\"]))\n\n        print('Average Accuracy (CNN):', sum(cnn_curve[\"top1\"])/len(cnn_curve[\"top1\"]))\n        logging.info(\"Average Accuracy (CNN): {} \\n\".format(sum(cnn_curve[\"top1\"])/len(cnn_curve[\"top1\"])))\nlogging.info(\"All History Accuracy (CNN): {} \\n\".format(all_his_acc))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T08:59:21.298019Z","iopub.execute_input":"2025-12-13T08:59:21.298434Z","iopub.status.idle":"2025-12-13T10:33:52.589571Z","shell.execute_reply.started":"2025-12-13T08:59:21.298414Z","shell.execute_reply":"2025-12-13T10:33:52.588599Z"}},"outputs":[{"name":"stdout","text":"Learning on 0-10\nTrain dataset size: 5000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"86,995,969 total parameters.\n1,197,313 training parameters.\nbackbone.blocks.0.adaptmlp.down_proj.weight 49152\nbackbone.blocks.0.adaptmlp.down_proj.bias 64\nbackbone.blocks.0.adaptmlp.up_proj.weight 49152\nbackbone.blocks.0.adaptmlp.up_proj.bias 768\nbackbone.blocks.1.adaptmlp.down_proj.weight 49152\nbackbone.blocks.1.adaptmlp.down_proj.bias 64\nbackbone.blocks.1.adaptmlp.up_proj.weight 49152\nbackbone.blocks.1.adaptmlp.up_proj.bias 768\nbackbone.blocks.2.adaptmlp.down_proj.weight 49152\nbackbone.blocks.2.adaptmlp.down_proj.bias 64\nbackbone.blocks.2.adaptmlp.up_proj.weight 49152\nbackbone.blocks.2.adaptmlp.up_proj.bias 768\nbackbone.blocks.3.adaptmlp.down_proj.weight 49152\nbackbone.blocks.3.adaptmlp.down_proj.bias 64\nbackbone.blocks.3.adaptmlp.up_proj.weight 49152\nbackbone.blocks.3.adaptmlp.up_proj.bias 768\nbackbone.blocks.4.adaptmlp.down_proj.weight 49152\nbackbone.blocks.4.adaptmlp.down_proj.bias 64\nbackbone.blocks.4.adaptmlp.up_proj.weight 49152\nbackbone.blocks.4.adaptmlp.up_proj.bias 768\nbackbone.blocks.5.adaptmlp.down_proj.weight 49152\nbackbone.blocks.5.adaptmlp.down_proj.bias 64\nbackbone.blocks.5.adaptmlp.up_proj.weight 49152\nbackbone.blocks.5.adaptmlp.up_proj.bias 768\nbackbone.blocks.6.adaptmlp.down_proj.weight 49152\nbackbone.blocks.6.adaptmlp.down_proj.bias 64\nbackbone.blocks.6.adaptmlp.up_proj.weight 49152\nbackbone.blocks.6.adaptmlp.up_proj.bias 768\nbackbone.blocks.7.adaptmlp.down_proj.weight 49152\nbackbone.blocks.7.adaptmlp.down_proj.bias 64\nbackbone.blocks.7.adaptmlp.up_proj.weight 49152\nbackbone.blocks.7.adaptmlp.up_proj.bias 768\nbackbone.blocks.8.adaptmlp.down_proj.weight 49152\nbackbone.blocks.8.adaptmlp.down_proj.bias 64\nbackbone.blocks.8.adaptmlp.up_proj.weight 49152\nbackbone.blocks.8.adaptmlp.up_proj.bias 768\nbackbone.blocks.9.adaptmlp.down_proj.weight 49152\nbackbone.blocks.9.adaptmlp.down_proj.bias 64\nbackbone.blocks.9.adaptmlp.up_proj.weight 49152\nbackbone.blocks.9.adaptmlp.up_proj.bias 768\nbackbone.blocks.10.adaptmlp.down_proj.weight 49152\nbackbone.blocks.10.adaptmlp.down_proj.bias 64\nbackbone.blocks.10.adaptmlp.up_proj.weight 49152\nbackbone.blocks.10.adaptmlp.up_proj.bias 768\nbackbone.blocks.11.adaptmlp.down_proj.weight 49152\nbackbone.blocks.11.adaptmlp.down_proj.bias 64\nbackbone.blocks.11.adaptmlp.up_proj.weight 49152\nbackbone.blocks.11.adaptmlp.up_proj.bias 768\nfc.weight 7680\nfc.sigma 1\nInitial training for the first task.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.15s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 0, Epoch 1/2 => Loss 2.200, Train_accy 58.24, Test_accy 96.10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 0, Epoch 2/2 => Loss 1.887, Train_accy 87.26, Test_accy 96.70\nThis is for the BaseNet initialization.\nI'm using ViT with adapters.\n_IncompatibleKeys(missing_keys=['blocks.0.adaptmlp.down_proj.weight', 'blocks.0.adaptmlp.down_proj.bias', 'blocks.0.adaptmlp.up_proj.weight', 'blocks.0.adaptmlp.up_proj.bias', 'blocks.1.adaptmlp.down_proj.weight', 'blocks.1.adaptmlp.down_proj.bias', 'blocks.1.adaptmlp.up_proj.weight', 'blocks.1.adaptmlp.up_proj.bias', 'blocks.2.adaptmlp.down_proj.weight', 'blocks.2.adaptmlp.down_proj.bias', 'blocks.2.adaptmlp.up_proj.weight', 'blocks.2.adaptmlp.up_proj.bias', 'blocks.3.adaptmlp.down_proj.weight', 'blocks.3.adaptmlp.down_proj.bias', 'blocks.3.adaptmlp.up_proj.weight', 'blocks.3.adaptmlp.up_proj.bias', 'blocks.4.adaptmlp.down_proj.weight', 'blocks.4.adaptmlp.down_proj.bias', 'blocks.4.adaptmlp.up_proj.weight', 'blocks.4.adaptmlp.up_proj.bias', 'blocks.5.adaptmlp.down_proj.weight', 'blocks.5.adaptmlp.down_proj.bias', 'blocks.5.adaptmlp.up_proj.weight', 'blocks.5.adaptmlp.up_proj.bias', 'blocks.6.adaptmlp.down_proj.weight', 'blocks.6.adaptmlp.down_proj.bias', 'blocks.6.adaptmlp.up_proj.weight', 'blocks.6.adaptmlp.up_proj.bias', 'blocks.7.adaptmlp.down_proj.weight', 'blocks.7.adaptmlp.down_proj.bias', 'blocks.7.adaptmlp.up_proj.weight', 'blocks.7.adaptmlp.up_proj.bias', 'blocks.8.adaptmlp.down_proj.weight', 'blocks.8.adaptmlp.down_proj.bias', 'blocks.8.adaptmlp.up_proj.weight', 'blocks.8.adaptmlp.up_proj.bias', 'blocks.9.adaptmlp.down_proj.weight', 'blocks.9.adaptmlp.down_proj.bias', 'blocks.9.adaptmlp.up_proj.weight', 'blocks.9.adaptmlp.up_proj.bias', 'blocks.10.adaptmlp.down_proj.weight', 'blocks.10.adaptmlp.down_proj.bias', 'blocks.10.adaptmlp.up_proj.weight', 'blocks.10.adaptmlp.up_proj.bias', 'blocks.11.adaptmlp.down_proj.weight', 'blocks.11.adaptmlp.down_proj.bias', 'blocks.11.adaptmlp.up_proj.weight', 'blocks.11.adaptmlp.up_proj.bias'], unexpected_keys=[])\nAfter BaseNet initialization.\nClear the backbone in MultiBranchCosineIncrementalNet, since we are using self.backbones with dual branches\nConstructed dual branch network.\nNew network structure:\nMultiBranchCosineIncrementalNet_adapt_AC(\n  (backbone): Identity()\n  (backbones): ModuleList(\n    (0): VisionTransformer(\n      (patch_embed): PatchEmbed(\n        (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n        (norm): Identity()\n      )\n      (pos_drop): Dropout(p=0.0, inplace=False)\n      (blocks): Sequential(\n        (0): Block(\n          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (act): GELU(approximate='none')\n          (mlp_drop): Dropout(p=0.0, inplace=False)\n          (adaptmlp): Adapter(\n            (down_proj): Linear(in_features=768, out_features=64, bias=True)\n            (non_linear_func): ReLU()\n            (up_proj): Linear(in_features=64, out_features=768, bias=True)\n          )\n        )\n        (1): Block(\n          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (act): GELU(approximate='none')\n          (mlp_drop): Dropout(p=0.0, inplace=False)\n          (adaptmlp): Adapter(\n            (down_proj): Linear(in_features=768, out_features=64, bias=True)\n            (non_linear_func): ReLU()\n            (up_proj): Linear(in_features=64, out_features=768, bias=True)\n          )\n        )\n        (2): Block(\n          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (act): GELU(approximate='none')\n          (mlp_drop): Dropout(p=0.0, inplace=False)\n          (adaptmlp): Adapter(\n            (down_proj): Linear(in_features=768, out_features=64, bias=True)\n            (non_linear_func): ReLU()\n            (up_proj): Linear(in_features=64, out_features=768, bias=True)\n          )\n        )\n        (3): Block(\n          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (act): GELU(approximate='none')\n          (mlp_drop): Dropout(p=0.0, inplace=False)\n          (adaptmlp): Adapter(\n            (down_proj): Linear(in_features=768, out_features=64, bias=True)\n            (non_linear_func): ReLU()\n            (up_proj): Linear(in_features=64, out_features=768, bias=True)\n          )\n        )\n        (4): Block(\n          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (act): GELU(approximate='none')\n          (mlp_drop): Dropout(p=0.0, inplace=False)\n          (adaptmlp): Adapter(\n            (down_proj): Linear(in_features=768, out_features=64, bias=True)\n            (non_linear_func): ReLU()\n            (up_proj): Linear(in_features=64, out_features=768, bias=True)\n          )\n        )\n        (5): Block(\n          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (act): GELU(approximate='none')\n          (mlp_drop): Dropout(p=0.0, inplace=False)\n          (adaptmlp): Adapter(\n            (down_proj): Linear(in_features=768, out_features=64, bias=True)\n            (non_linear_func): ReLU()\n            (up_proj): Linear(in_features=64, out_features=768, bias=True)\n          )\n        )\n        (6): Block(\n          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (act): GELU(approximate='none')\n          (mlp_drop): Dropout(p=0.0, inplace=False)\n          (adaptmlp): Adapter(\n            (down_proj): Linear(in_features=768, out_features=64, bias=True)\n            (non_linear_func): ReLU()\n            (up_proj): Linear(in_features=64, out_features=768, bias=True)\n          )\n        )\n        (7): Block(\n          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (act): GELU(approximate='none')\n          (mlp_drop): Dropout(p=0.0, inplace=False)\n          (adaptmlp): Adapter(\n            (down_proj): Linear(in_features=768, out_features=64, bias=True)\n            (non_linear_func): ReLU()\n            (up_proj): Linear(in_features=64, out_features=768, bias=True)\n          )\n        )\n        (8): Block(\n          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (act): GELU(approximate='none')\n          (mlp_drop): Dropout(p=0.0, inplace=False)\n          (adaptmlp): Adapter(\n            (down_proj): Linear(in_features=768, out_features=64, bias=True)\n            (non_linear_func): ReLU()\n            (up_proj): Linear(in_features=64, out_features=768, bias=True)\n          )\n        )\n        (9): Block(\n          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (act): GELU(approximate='none')\n          (mlp_drop): Dropout(p=0.0, inplace=False)\n          (adaptmlp): Adapter(\n            (down_proj): Linear(in_features=768, out_features=64, bias=True)\n            (non_linear_func): ReLU()\n            (up_proj): Linear(in_features=64, out_features=768, bias=True)\n          )\n        )\n        (10): Block(\n          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (act): GELU(approximate='none')\n          (mlp_drop): Dropout(p=0.0, inplace=False)\n          (adaptmlp): Adapter(\n            (down_proj): Linear(in_features=768, out_features=64, bias=True)\n            (non_linear_func): ReLU()\n            (up_proj): Linear(in_features=64, out_features=768, bias=True)\n          )\n        )\n        (11): Block(\n          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (act): GELU(approximate='none')\n          (mlp_drop): Dropout(p=0.0, inplace=False)\n          (adaptmlp): Adapter(\n            (down_proj): Linear(in_features=768, out_features=64, bias=True)\n            (non_linear_func): ReLU()\n            (up_proj): Linear(in_features=64, out_features=768, bias=True)\n          )\n        )\n      )\n      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (pre_logits): Identity()\n      (head): Identity()\n    )\n  )\n  (fc): CosineLinear2()\n)\nUse AC model as classifier head.\nAC model architecture: AC_Linear(\n  (fc): Sequential(\n    (0): Linear(in_features=768, out_features=5000, bias=False)\n    (1): ReLU()\n    (2): Linear(in_features=5000, out_features=10, bias=False)\n  )\n)\nComputing class means and covariance matrices...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 0 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 1 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 2 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 3 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 4 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 5 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 6 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 7 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 8 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 9 covariance matrix shape: (768, 768)\nStarting class alignment...\n","output_type":"stream"},{"name":"stderr","text":"Alignment: 100%|██████████| 53/53 [00:33<00:00,  1.60batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Embedding shape:  torch.Size([5000, 5000])\nLabel shape torch.Size([5000])\nOne-hot label shape:  torch.Size([5000, 10])\nOptimising ridge parameter...\nselected lambda = 1000.0\ngamma 1000.0\nnumpy inverse\nFinish one task \nAverage Accuracy (CNN): 97.4\nLearning on 10-20\nTrain dataset size: 5000\nUse Cosine model as classifier head.\nCosine model architecture: CosineLinear2()\nOld weight (Cosine FC) torch.Size([10, 768])\nNew weight (Cosine FC) torch.Size([20, 768])\nUse AC model as classifier head.\nAC model architecture: AC_Linear(\n  (fc): Sequential(\n    (0): Linear(in_features=768, out_features=5000, bias=False)\n    (1): ReLU()\n    (2): Linear(in_features=5000, out_features=20, bias=False)\n  )\n)\nHidden weight (AC model) torch.Size([5000, 768])\nOld weight (AC model) torch.Size([10, 5000])\nNew weight (AC model) torch.Size([20, 5000])\n90,943,649 total parameters.\n1,204,993 training parameters.\nProgressive training for task 1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 1, Epoch 1/2 => Loss 2.244, Train_accy 80.84, Test_accy 45.70\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.15s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 1, Epoch 2/2 => Loss 1.633, Train_accy 82.60, Test_accy 45.90\nTask 1, Epoch 2/2 => Loss 1.633, Train_accy 82.60, Test_accy 45.90\nComputing class means and covariance matrices...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 10 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 11 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 12 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 13 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 14 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 15 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 16 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 17 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 18 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 19 covariance matrix shape: (768, 768)\nCalibrating prototype model (Prototype correction - Knowledge Rumination)...\n","output_type":"stream"},{"name":"stderr","text":"cali_prototye_model: 100%|██████████| 53/53 [01:03<00:00,  1.20s/batch]\n  0%|          | 0/1000 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"开始 修正 prototype\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1000/1000 [03:01<00:00,  5.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"best_loss: 0.04433102217316628\nComputing class relations...\nOld means shape: (10, 768)\nNew means shape: (10, 768)\nClass relations: [17 12 12 18 11 16 11 16 15 11]\nBuilding feature dataset...\nExtract prototypes for known classes...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nGenerating pseudo-features for old classes from relations...\nTotal feature dataset size: 10000\nFeature dataset dimension: 768\nLabel dataset size: 10000\nLabel dataset classes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\nIncremental class alignment (Knowledge Memorization)...\n","output_type":"stream"},{"name":"stderr","text":"Alignment: 100%|██████████| 53/53 [00:34<00:00,  1.55batch/s]","output_type":"stream"},{"name":"stdout","text":"Knowledge Memorization completed.\nUpdated weight matrix W shape: torch.Size([5000, 20])\nUpdated correlation matrix R shape: torch.Size([5000, 5000])\nnumpy inverse\nCalibrating classifier weights (Knowledge Rumination - Selective reinforcement of old task knowledge)...\n","output_type":"stream"},{"name":"stderr","text":"\nAlignment: 100%|██████████| 105/105 [00:03<00:00, 27.99batch/s]","output_type":"stream"},{"name":"stdout","text":"numpy inverse\nFinish one task \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Average Accuracy (CNN): 96.975\nLearning on 20-30\nTrain dataset size: 5000\nUse Cosine model as classifier head.\nCosine model architecture: CosineLinear2()\nOld weight (Cosine FC) torch.Size([20, 768])\nNew weight (Cosine FC) torch.Size([30, 768])\nUse AC model as classifier head.\nAC model architecture: AC_Linear(\n  (fc): Sequential(\n    (0): Linear(in_features=768, out_features=5000, bias=False)\n    (1): ReLU()\n    (2): Linear(in_features=5000, out_features=30, bias=False)\n  )\n)\nHidden weight (AC model) torch.Size([5000, 768])\nOld weight (AC model) torch.Size([20, 5000])\nNew weight (AC model) torch.Size([30, 5000])\n91,001,329 total parameters.\n1,212,673 training parameters.\nProgressive training for task 2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 2, Epoch 1/2 => Loss 2.102, Train_accy 72.36, Test_accy 56.10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 2, Epoch 2/2 => Loss 1.860, Train_accy 74.78, Test_accy 56.23\nTask 2, Epoch 2/2 => Loss 1.860, Train_accy 74.78, Test_accy 56.23\nComputing class means and covariance matrices...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 20 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 21 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 22 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 23 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 24 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 25 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 26 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 27 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 28 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 29 covariance matrix shape: (768, 768)\nCalibrating prototype model (Prototype correction - Knowledge Rumination)...\n","output_type":"stream"},{"name":"stderr","text":"cali_prototye_model: 100%|██████████| 53/53 [01:03<00:00,  1.20s/batch]\n  0%|          | 1/1000 [00:00<03:09,  5.27it/s]","output_type":"stream"},{"name":"stdout","text":"开始 修正 prototype\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1000/1000 [03:01<00:00,  5.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"best_loss: 0.043666117757558826\nComputing class relations...\nOld means shape: (20, 768)\nNew means shape: (10, 768)\nClass relations: [26 21 28 28 23 27 26 23 25 26 25 21 21 27 21 28 20 24 27 27]\nBuilding feature dataset...\nExtract prototypes for known classes...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nGenerating pseudo-features for old classes from relations...\nTotal feature dataset size: 15000\nFeature dataset dimension: 768\nLabel dataset size: 15000\nLabel dataset classes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29]\nIncremental class alignment (Knowledge Memorization)...\n","output_type":"stream"},{"name":"stderr","text":"Alignment: 100%|██████████| 53/53 [00:33<00:00,  1.56batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Knowledge Memorization completed.\nUpdated weight matrix W shape: torch.Size([5000, 30])\nUpdated correlation matrix R shape: torch.Size([5000, 5000])\nnumpy inverse\nCalibrating classifier weights (Knowledge Rumination - Selective reinforcement of old task knowledge)...\n","output_type":"stream"},{"name":"stderr","text":"Alignment: 100%|██████████| 157/157 [00:05<00:00, 28.99batch/s]","output_type":"stream"},{"name":"stdout","text":"numpy inverse\nFinish one task \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Average Accuracy (CNN): 96.09333333333332\nLearning on 30-40\nTrain dataset size: 5000\nUse Cosine model as classifier head.\nCosine model architecture: CosineLinear2()\nOld weight (Cosine FC) torch.Size([30, 768])\nNew weight (Cosine FC) torch.Size([40, 768])\nUse AC model as classifier head.\nAC model architecture: AC_Linear(\n  (fc): Sequential(\n    (0): Linear(in_features=768, out_features=5000, bias=False)\n    (1): ReLU()\n    (2): Linear(in_features=5000, out_features=40, bias=False)\n  )\n)\nHidden weight (AC model) torch.Size([5000, 768])\nOld weight (AC model) torch.Size([30, 5000])\nNew weight (AC model) torch.Size([40, 5000])\n91,059,009 total parameters.\n1,220,353 training parameters.\nProgressive training for task 3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 3, Epoch 1/2 => Loss 2.083, Train_accy 73.86, Test_accy 61.85\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 3, Epoch 2/2 => Loss 1.833, Train_accy 75.82, Test_accy 62.35\nTask 3, Epoch 2/2 => Loss 1.833, Train_accy 75.82, Test_accy 62.35\nComputing class means and covariance matrices...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 30 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 31 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 32 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 33 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 34 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 35 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 36 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 37 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 38 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 39 covariance matrix shape: (768, 768)\nCalibrating prototype model (Prototype correction - Knowledge Rumination)...\n","output_type":"stream"},{"name":"stderr","text":"cali_prototye_model: 100%|██████████| 53/53 [01:03<00:00,  1.20s/batch]\n  0%|          | 1/1000 [00:00<03:02,  5.47it/s]","output_type":"stream"},{"name":"stdout","text":"开始 修正 prototype\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1000/1000 [03:02<00:00,  5.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"best_loss: 0.04276747187972069\nComputing class relations...\nOld means shape: (30, 768)\nNew means shape: (10, 768)\nClass relations: [34 33 32 31 39 38 34 36 34 34 33 33 33 38 36 32 37 37 38 38 37 36 37 39\n 37 34 34 37 32 32]\nBuilding feature dataset...\nExtract prototypes for known classes...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nGenerating pseudo-features for old classes from relations...\nTotal feature dataset size: 20000\nFeature dataset dimension: 768\nLabel dataset size: 20000\nLabel dataset classes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\nIncremental class alignment (Knowledge Memorization)...\n","output_type":"stream"},{"name":"stderr","text":"Alignment: 100%|██████████| 53/53 [00:34<00:00,  1.56batch/s]","output_type":"stream"},{"name":"stdout","text":"Knowledge Memorization completed.\nUpdated weight matrix W shape: torch.Size([5000, 40])\nUpdated correlation matrix R shape: torch.Size([5000, 5000])\nnumpy inverse\nCalibrating classifier weights (Knowledge Rumination - Selective reinforcement of old task knowledge)...\n","output_type":"stream"},{"name":"stderr","text":"\nAlignment: 100%|██████████| 209/209 [00:07<00:00, 28.99batch/s]","output_type":"stream"},{"name":"stdout","text":"numpy inverse\nFinish one task \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Average Accuracy (CNN): 95.19999999999999\nLearning on 40-50\nTrain dataset size: 5000\nUse Cosine model as classifier head.\nCosine model architecture: CosineLinear2()\nOld weight (Cosine FC) torch.Size([40, 768])\nNew weight (Cosine FC) torch.Size([50, 768])\nUse AC model as classifier head.\nAC model architecture: AC_Linear(\n  (fc): Sequential(\n    (0): Linear(in_features=768, out_features=5000, bias=False)\n    (1): ReLU()\n    (2): Linear(in_features=5000, out_features=50, bias=False)\n  )\n)\nHidden weight (AC model) torch.Size([5000, 768])\nOld weight (AC model) torch.Size([40, 5000])\nNew weight (AC model) torch.Size([50, 5000])\n91,116,689 total parameters.\n1,228,033 training parameters.\nProgressive training for task 4\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 4, Epoch 1/2 => Loss 2.061, Train_accy 70.04, Test_accy 65.20\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 4, Epoch 2/2 => Loss 1.803, Train_accy 73.24, Test_accy 65.76\nTask 4, Epoch 2/2 => Loss 1.803, Train_accy 73.24, Test_accy 65.76\nComputing class means and covariance matrices...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 40 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 41 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 42 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 43 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 44 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 45 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 46 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 47 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 48 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 49 covariance matrix shape: (768, 768)\nCalibrating prototype model (Prototype correction - Knowledge Rumination)...\n","output_type":"stream"},{"name":"stderr","text":"cali_prototye_model: 100%|██████████| 53/53 [01:03<00:00,  1.20s/batch]\n  0%|          | 1/1000 [00:00<03:01,  5.52it/s]","output_type":"stream"},{"name":"stdout","text":"开始 修正 prototype\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1000/1000 [03:01<00:00,  5.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"best_loss: 0.04451894924044609\nComputing class relations...\nOld means shape: (40, 768)\nNew means shape: (10, 768)\nClass relations: [43 40 40 40 49 45 43 49 43 43 41 43 40 48 49 41 49 43 49 48 49 49 49 49\n 49 41 43 49 46 41 46 40 41 41 43 46 49 49 48 49]\nBuilding feature dataset...\nExtract prototypes for known classes...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nGenerating pseudo-features for old classes from relations...\nTotal feature dataset size: 25000\nFeature dataset dimension: 768\nLabel dataset size: 25000\nLabel dataset classes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n 48 49]\nIncremental class alignment (Knowledge Memorization)...\n","output_type":"stream"},{"name":"stderr","text":"Alignment: 100%|██████████| 53/53 [00:34<00:00,  1.55batch/s]","output_type":"stream"},{"name":"stdout","text":"Knowledge Memorization completed.\nUpdated weight matrix W shape: torch.Size([5000, 50])\nUpdated correlation matrix R shape: torch.Size([5000, 5000])\nnumpy inverse\nCalibrating classifier weights (Knowledge Rumination - Selective reinforcement of old task knowledge)...\n","output_type":"stream"},{"name":"stderr","text":"\nAlignment: 100%|██████████| 261/261 [00:09<00:00, 28.83batch/s]","output_type":"stream"},{"name":"stdout","text":"numpy inverse\nFinish one task \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Average Accuracy (CNN): 94.332\nLearning on 50-60\nTrain dataset size: 5000\nUse Cosine model as classifier head.\nCosine model architecture: CosineLinear2()\nOld weight (Cosine FC) torch.Size([50, 768])\nNew weight (Cosine FC) torch.Size([60, 768])\nUse AC model as classifier head.\nAC model architecture: AC_Linear(\n  (fc): Sequential(\n    (0): Linear(in_features=768, out_features=5000, bias=False)\n    (1): ReLU()\n    (2): Linear(in_features=5000, out_features=60, bias=False)\n  )\n)\nHidden weight (AC model) torch.Size([5000, 768])\nOld weight (AC model) torch.Size([50, 5000])\nNew weight (AC model) torch.Size([60, 5000])\n91,174,369 total parameters.\n1,235,713 training parameters.\nProgressive training for task 5\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 5, Epoch 1/2 => Loss 2.190, Train_accy 62.76, Test_accy 66.08\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 5, Epoch 2/2 => Loss 1.910, Train_accy 66.88, Test_accy 66.40\nTask 5, Epoch 2/2 => Loss 1.910, Train_accy 66.88, Test_accy 66.40\nComputing class means and covariance matrices...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 50 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 51 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 52 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 53 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 54 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 55 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 56 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 57 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 58 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 59 covariance matrix shape: (768, 768)\nCalibrating prototype model (Prototype correction - Knowledge Rumination)...\n","output_type":"stream"},{"name":"stderr","text":"cali_prototye_model: 100%|██████████| 53/53 [01:03<00:00,  1.20s/batch]\n  0%|          | 1/1000 [00:00<02:59,  5.56it/s]","output_type":"stream"},{"name":"stdout","text":"开始 修正 prototype\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1000/1000 [03:00<00:00,  5.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"best_loss: 0.042911649256944656\nComputing class relations...\nOld means shape: (50, 768)\nNew means shape: (10, 768)\nClass relations: [58 50 54 51 52 55 58 52 57 57 54 50 54 56 50 54 55 57 56 55 55 50 56 52\n 50 57 57 56 53 59 54 51 54 54 57 59 52 55 55 52 50 57 57 57 54 56 59 57\n 56 52]\nBuilding feature dataset...\nExtract prototypes for known classes...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nGenerating pseudo-features for old classes from relations...\nTotal feature dataset size: 30000\nFeature dataset dimension: 768\nLabel dataset size: 30000\nLabel dataset classes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n 48 49 50 51 52 53 54 55 56 57 58 59]\nIncremental class alignment (Knowledge Memorization)...\n","output_type":"stream"},{"name":"stderr","text":"Alignment: 100%|██████████| 53/53 [00:34<00:00,  1.56batch/s]","output_type":"stream"},{"name":"stdout","text":"Knowledge Memorization completed.\nUpdated weight matrix W shape: torch.Size([5000, 60])\nUpdated correlation matrix R shape: torch.Size([5000, 5000])\nnumpy inverse\nCalibrating classifier weights (Knowledge Rumination - Selective reinforcement of old task knowledge)...\n","output_type":"stream"},{"name":"stderr","text":"\nAlignment: 100%|██████████| 313/313 [00:10<00:00, 28.99batch/s]","output_type":"stream"},{"name":"stdout","text":"numpy inverse\nFinish one task \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Average Accuracy (CNN): 93.62166666666667\nLearning on 60-70\nTrain dataset size: 5000\nUse Cosine model as classifier head.\nCosine model architecture: CosineLinear2()\nOld weight (Cosine FC) torch.Size([60, 768])\nNew weight (Cosine FC) torch.Size([70, 768])\nUse AC model as classifier head.\nAC model architecture: AC_Linear(\n  (fc): Sequential(\n    (0): Linear(in_features=768, out_features=5000, bias=False)\n    (1): ReLU()\n    (2): Linear(in_features=5000, out_features=70, bias=False)\n  )\n)\nHidden weight (AC model) torch.Size([5000, 768])\nOld weight (AC model) torch.Size([60, 5000])\nNew weight (AC model) torch.Size([70, 5000])\n91,232,049 total parameters.\n1,243,393 training parameters.\nProgressive training for task 6\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 6, Epoch 1/2 => Loss 2.594, Train_accy 48.60, Test_accy 64.54\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 6, Epoch 2/2 => Loss 2.329, Train_accy 54.06, Test_accy 65.01\nTask 6, Epoch 2/2 => Loss 2.329, Train_accy 54.06, Test_accy 65.01\nComputing class means and covariance matrices...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 60 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 61 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 62 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 63 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 64 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 65 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 66 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 67 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 68 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 69 covariance matrix shape: (768, 768)\nCalibrating prototype model (Prototype correction - Knowledge Rumination)...\n","output_type":"stream"},{"name":"stderr","text":"cali_prototye_model: 100%|██████████| 53/53 [01:03<00:00,  1.20s/batch]\n  0%|          | 1/1000 [00:00<02:59,  5.58it/s]","output_type":"stream"},{"name":"stdout","text":"开始 修正 prototype\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1000/1000 [03:01<00:00,  5.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"best_loss: 0.0455656024813652\nComputing class relations...\nOld means shape: (60, 768)\nNew means shape: (10, 768)\nClass relations: [62 63 65 68 63 68 61 60 64 64 65 63 65 68 60 65 66 60 68 68 66 63 68 63\n 63 62 64 68 65 65 65 66 65 65 64 69 63 66 68 63 63 62 61 64 60 68 69 62\n 68 60 63 65 63 69 65 68 68 62 62 69]\nBuilding feature dataset...\nExtract prototypes for known classes...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nGenerating pseudo-features for old classes from relations...\nTotal feature dataset size: 35000\nFeature dataset dimension: 768\nLabel dataset size: 35000\nLabel dataset classes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]\nIncremental class alignment (Knowledge Memorization)...\n","output_type":"stream"},{"name":"stderr","text":"Alignment: 100%|██████████| 53/53 [00:33<00:00,  1.56batch/s]","output_type":"stream"},{"name":"stdout","text":"Knowledge Memorization completed.\nUpdated weight matrix W shape: torch.Size([5000, 70])\nUpdated correlation matrix R shape: torch.Size([5000, 5000])\nnumpy inverse\nCalibrating classifier weights (Knowledge Rumination - Selective reinforcement of old task knowledge)...\n","output_type":"stream"},{"name":"stderr","text":"\nAlignment: 100%|██████████| 365/365 [00:12<00:00, 28.88batch/s]","output_type":"stream"},{"name":"stdout","text":"numpy inverse\nFinish one task \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Average Accuracy (CNN): 92.82714285714285\nLearning on 70-80\nTrain dataset size: 5000\nUse Cosine model as classifier head.\nCosine model architecture: CosineLinear2()\nOld weight (Cosine FC) torch.Size([70, 768])\nNew weight (Cosine FC) torch.Size([80, 768])\nUse AC model as classifier head.\nAC model architecture: AC_Linear(\n  (fc): Sequential(\n    (0): Linear(in_features=768, out_features=5000, bias=False)\n    (1): ReLU()\n    (2): Linear(in_features=5000, out_features=80, bias=False)\n  )\n)\nHidden weight (AC model) torch.Size([5000, 768])\nOld weight (AC model) torch.Size([70, 5000])\nNew weight (AC model) torch.Size([80, 5000])\n91,289,729 total parameters.\n1,251,073 training parameters.\nProgressive training for task 7\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 7, Epoch 1/2 => Loss 2.482, Train_accy 54.52, Test_accy 64.66\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 7, Epoch 2/2 => Loss 2.143, Train_accy 60.84, Test_accy 65.20\nTask 7, Epoch 2/2 => Loss 2.143, Train_accy 60.84, Test_accy 65.20\nComputing class means and covariance matrices...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 70 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 71 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 72 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 73 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 74 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 75 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 76 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 77 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 78 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 79 covariance matrix shape: (768, 768)\nCalibrating prototype model (Prototype correction - Knowledge Rumination)...\n","output_type":"stream"},{"name":"stderr","text":"cali_prototye_model: 100%|██████████| 53/53 [01:03<00:00,  1.20s/batch]\n  0%|          | 1/1000 [00:00<03:10,  5.24it/s]","output_type":"stream"},{"name":"stdout","text":"开始 修正 prototype\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1000/1000 [03:01<00:00,  5.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"best_loss: 0.04350857010483742\nComputing class relations...\nOld means shape: (70, 768)\nNew means shape: (10, 768)\nClass relations: [76 78 76 77 75 77 70 72 79 76 76 73 79 77 73 76 77 77 77 77 77 73 77 78\n 78 76 76 77 74 74 74 77 76 76 76 71 78 77 77 72 78 76 79 76 73 77 74 76\n 77 78 78 77 72 74 76 77 77 76 79 74 78 76 76 78 71 76 77 76 77 74]\nBuilding feature dataset...\nExtract prototypes for known classes...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nGenerating pseudo-features for old classes from relations...\nTotal feature dataset size: 40000\nFeature dataset dimension: 768\nLabel dataset size: 40000\nLabel dataset classes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n 72 73 74 75 76 77 78 79]\nIncremental class alignment (Knowledge Memorization)...\n","output_type":"stream"},{"name":"stderr","text":"Alignment: 100%|██████████| 53/53 [00:33<00:00,  1.56batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Knowledge Memorization completed.\nUpdated weight matrix W shape: torch.Size([5000, 80])\nUpdated correlation matrix R shape: torch.Size([5000, 5000])\nnumpy inverse\nCalibrating classifier weights (Knowledge Rumination - Selective reinforcement of old task knowledge)...\n","output_type":"stream"},{"name":"stderr","text":"Alignment: 100%|██████████| 417/417 [00:14<00:00, 28.77batch/s]\n","output_type":"stream"},{"name":"stdout","text":"numpy inverse\nFinish one task \nAverage Accuracy (CNN): 92.0675\nLearning on 80-90\nTrain dataset size: 5000\nUse Cosine model as classifier head.\nCosine model architecture: CosineLinear2()\nOld weight (Cosine FC) torch.Size([80, 768])\nNew weight (Cosine FC) torch.Size([90, 768])\nUse AC model as classifier head.\nAC model architecture: AC_Linear(\n  (fc): Sequential(\n    (0): Linear(in_features=768, out_features=5000, bias=False)\n    (1): ReLU()\n    (2): Linear(in_features=5000, out_features=90, bias=False)\n  )\n)\nHidden weight (AC model) torch.Size([5000, 768])\nOld weight (AC model) torch.Size([80, 5000])\nNew weight (AC model) torch.Size([90, 5000])\n91,347,409 total parameters.\n1,258,753 training parameters.\nProgressive training for task 8\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.15s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 8, Epoch 1/2 => Loss 2.177, Train_accy 66.74, Test_accy 64.91\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 8, Epoch 2/2 => Loss 1.643, Train_accy 74.32, Test_accy 63.78\nTask 8, Epoch 2/2 => Loss 1.643, Train_accy 74.32, Test_accy 63.78\nComputing class means and covariance matrices...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 80 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 81 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 82 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 83 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 84 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 85 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 86 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 87 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 88 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 89 covariance matrix shape: (768, 768)\nCalibrating prototype model (Prototype correction - Knowledge Rumination)...\n","output_type":"stream"},{"name":"stderr","text":"cali_prototye_model: 100%|██████████| 53/53 [01:03<00:00,  1.20s/batch]\n  0%|          | 1/1000 [00:00<02:58,  5.58it/s]","output_type":"stream"},{"name":"stdout","text":"开始 修正 prototype\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1000/1000 [03:01<00:00,  5.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"best_loss: 0.044009780108928684\nComputing class relations...\nOld means shape: (80, 768)\nNew means shape: (10, 768)\nClass relations: [82 86 87 88 86 84 82 88 80 80 87 86 85 84 86 87 84 80 88 85 84 86 84 86\n 86 89 80 84 87 87 87 88 87 86 80 87 83 84 85 83 86 80 80 80 86 84 87 80\n 85 86 86 88 86 87 87 84 84 80 82 87 86 80 89 86 80 87 84 87 85 87 89 80\n 83 86 87 83 80 84 86 80]\nBuilding feature dataset...\nExtract prototypes for known classes...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nGenerating pseudo-features for old classes from relations...\nTotal feature dataset size: 45000\nFeature dataset dimension: 768\nLabel dataset size: 45000\nLabel dataset classes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]\nIncremental class alignment (Knowledge Memorization)...\n","output_type":"stream"},{"name":"stderr","text":"Alignment: 100%|██████████| 53/53 [00:34<00:00,  1.55batch/s]","output_type":"stream"},{"name":"stdout","text":"Knowledge Memorization completed.\nUpdated weight matrix W shape: torch.Size([5000, 90])\nUpdated correlation matrix R shape: torch.Size([5000, 5000])\nnumpy inverse\nCalibrating classifier weights (Knowledge Rumination - Selective reinforcement of old task knowledge)...\n","output_type":"stream"},{"name":"stderr","text":"\nAlignment: 100%|██████████| 469/469 [00:16<00:00, 28.94batch/s]","output_type":"stream"},{"name":"stdout","text":"numpy inverse\nFinish one task \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Average Accuracy (CNN): 91.32777777777777\nLearning on 90-100\nTrain dataset size: 5000\nUse Cosine model as classifier head.\nCosine model architecture: CosineLinear2()\nOld weight (Cosine FC) torch.Size([90, 768])\nNew weight (Cosine FC) torch.Size([100, 768])\nUse AC model as classifier head.\nAC model architecture: AC_Linear(\n  (fc): Sequential(\n    (0): Linear(in_features=768, out_features=5000, bias=False)\n    (1): ReLU()\n    (2): Linear(in_features=5000, out_features=100, bias=False)\n  )\n)\nHidden weight (AC model) torch.Size([5000, 768])\nOld weight (AC model) torch.Size([90, 5000])\nNew weight (AC model) torch.Size([100, 5000])\n91,405,089 total parameters.\n1,266,433 training parameters.\nProgressive training for task 9\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 9, Epoch 1/2 => Loss 2.263, Train_accy 56.22, Test_accy 64.82\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [01:00<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Task 9, Epoch 2/2 => Loss 1.750, Train_accy 62.60, Test_accy 64.00\nTask 9, Epoch 2/2 => Loss 1.750, Train_accy 62.60, Test_accy 64.00\nComputing class means and covariance matrices...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 90 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 91 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 92 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 93 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 94 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 95 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 96 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 97 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 98 covariance matrix shape: (768, 768)\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nClass 99 covariance matrix shape: (768, 768)\nCalibrating prototype model (Prototype correction - Knowledge Rumination)...\n","output_type":"stream"},{"name":"stderr","text":"cali_prototye_model: 100%|██████████| 53/53 [01:03<00:00,  1.20s/batch]\n  0%|          | 0/1000 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"开始 修正 prototype\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1000/1000 [03:00<00:00,  5.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"best_loss: 0.04290770229697227\nComputing class relations...\nOld means shape: (90, 768)\nNew means shape: (10, 768)\nClass relations: [97 91 91 95 92 99 97 99 97 92 98 93 91 99 92 98 99 92 99 98 99 93 99 99\n 93 97 97 99 98 98 98 95 98 91 97 94 99 93 99 90 91 97 92 97 91 99 98 97\n 99 99 93 95 92 98 91 99 99 97 97 99 99 98 97 93 94 98 93 98 99 98 97 94\n 90 92 99 90 97 99 93 96 97 90 97 90 99 99 93 98 95 98]\nBuilding feature dataset...\nExtract prototypes for known classes...\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nExtracting prototypes...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracted vectors shape: (500, 768) float32\nExtracted targets shape: (500,) int64\nGenerating pseudo-features for old classes from relations...\nTotal feature dataset size: 50000\nFeature dataset dimension: 768\nLabel dataset size: 50000\nLabel dataset classes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n 96 97 98 99]\nIncremental class alignment (Knowledge Memorization)...\n","output_type":"stream"},{"name":"stderr","text":"Alignment: 100%|██████████| 53/53 [00:34<00:00,  1.56batch/s]","output_type":"stream"},{"name":"stdout","text":"Knowledge Memorization completed.\nUpdated weight matrix W shape: torch.Size([5000, 100])\nUpdated correlation matrix R shape: torch.Size([5000, 5000])\nnumpy inverse\nCalibrating classifier weights (Knowledge Rumination - Selective reinforcement of old task knowledge)...\n","output_type":"stream"},{"name":"stderr","text":"\nAlignment: 100%|██████████| 521/521 [00:18<00:00, 28.48batch/s]","output_type":"stream"},{"name":"stdout","text":"numpy inverse\nFinish one task \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Average Accuracy (CNN): 90.655\n","output_type":"stream"}],"execution_count":8}]}